{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e078a52",
   "metadata": {},
   "source": [
    "# JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e361432d",
   "metadata": {},
   "source": [
    "## Bu dastur yangi JSON fayllar kelganida ularni asosiy ma'lumotlar bazasiga qo'shib turadi va ID konflikti bo'lmasligini ta'minlaydi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6f53159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Audio Ma'lumotlar Boshqaruvchi ===\n",
      "1. Bitta fayl qo'shish\n",
      "2. Papkadan barcha fayllarni qo'shish\n",
      "3. Statistikalarni ko'rish\n",
      "4. Ma'lumotlarni saqlash va chiqish\n",
      "\n",
      "Tanlang (1-4): 2\n",
      "Papka yo'lini kiriting: drive-download-20250915T152939Z-1-001\n",
      "Topildi: 6 ta JSON fayl\n",
      "‚úì Qo'shildi: 20250912T124701_7fe961d1.json -> ID: 20250912T124701_7fe961d1_1\n",
      "‚úì Qo'shildi: 20250912T124632_fa67e4df.json -> ID: 20250912T124632_fa67e4df_1\n",
      "‚úì Qo'shildi: 20250912T134506_b09de6d4.json -> ID: 20250912T134506_b09de6d4_1\n",
      "‚úì Qo'shildi: 20250912T124607_d9fafe5d.json -> ID: 20250912T124607_d9fafe5d_1\n",
      "‚úì Qo'shildi: 20250912T134443_c3bdac14.json -> ID: 20250912T134443_c3bdac14_1\n",
      "‚úì Qo'shildi: 20250912T134342_343b1c6d.json -> ID: 20250912T134342_343b1c6d_1\n",
      "\n",
      "Natija: 6 muvaffaqiyatli, 0 xato\n",
      "\n",
      "Tanlang (1-4): 3\n",
      "\n",
      "=== Statistikalar ===\n",
      "Jami yozuvlar: 12\n",
      "Kategoriyalar: {'work': 2, 'travel': 2, 'sport': 2, 'daily': 2, 'culture': 2, 'education': 2}\n",
      "Kayfiyat: {'positive': 8, 'negative': 4}\n",
      "So'nggi yangilanish: 2025-09-16T22:18:05.741345\n",
      "\n",
      "Tanlang (1-4): 4\n",
      "Ma'lumotlar saqlandi. Dastur tugadi.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "class AudioDataManager:\n",
    "    def __init__(self, main_db_path: str = \"main_audio_database.json\"):\n",
    "        \"\"\"\n",
    "        Audio ma'lumotlarni boshqaruvchi sinf\n",
    "        main_db_path: asosiy ma'lumotlar bazasi fayl yo'li\n",
    "        \"\"\"\n",
    "        self.main_db_path = main_db_path\n",
    "        self.main_database = self.load_main_database()\n",
    "    \n",
    "    def load_main_database(self) -> Dict[str, Any]:\n",
    "        \"\"\"Asosiy ma'lumotlar bazasini yuklash\"\"\"\n",
    "        if os.path.exists(self.main_db_path):\n",
    "            try:\n",
    "                with open(self.main_db_path, 'r', encoding='utf-8') as file:\n",
    "                    data = json.load(file)\n",
    "                    # Agar data dict bo'lmasa, yangi format yaratamiz\n",
    "                    if isinstance(data, list):\n",
    "                        # Eski formatdan yangi formatga o'tkazish\n",
    "                        new_format = {\n",
    "                            \"metadata\": {\n",
    "                                \"total_records\": len(data),\n",
    "                                \"last_updated\": datetime.now().isoformat(),\n",
    "                                \"version\": \"1.0\"\n",
    "                            },\n",
    "                            \"records\": {item.get(\"utt_id\", f\"record_{i}\"): item \n",
    "                                      for i, item in enumerate(data)}\n",
    "                        }\n",
    "                        self.save_main_database(new_format)\n",
    "                        return new_format\n",
    "                    return data\n",
    "            except (json.JSONDecodeError, FileNotFoundError):\n",
    "                pass\n",
    "        \n",
    "        # Yangi ma'lumotlar bazasi yaratish\n",
    "        return {\n",
    "            \"metadata\": {\n",
    "                \"total_records\": 0,\n",
    "                \"last_updated\": datetime.now().isoformat(),\n",
    "                \"version\": \"1.0\"\n",
    "            },\n",
    "            \"records\": {}\n",
    "        }\n",
    "    \n",
    "    def save_main_database(self, data: Dict[str, Any] = None):\n",
    "        \"\"\"Ma'lumotlar bazasini saqlash\"\"\"\n",
    "        if data is None:\n",
    "            data = self.main_database\n",
    "        \n",
    "        with open(self.main_db_path, 'w', encoding='utf-8') as file:\n",
    "            json.dump(data, file, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    def generate_unique_id(self, record: Dict[str, Any], filename: str) -> str:\n",
    "        \"\"\"Noyob ID yaratish\"\"\"\n",
    "        # Agar utt_id mavjud bo'lsa, uni ishlatamiz\n",
    "        if \"utt_id\" in record and record[\"utt_id\"]:\n",
    "            base_id = record[\"utt_id\"]\n",
    "        else:\n",
    "            # Fayl nomidan ID yaratish\n",
    "            base_id = os.path.splitext(filename)[0]\n",
    "        \n",
    "        # Agar ID allaqachon mavjud bo'lsa, noyob qilish\n",
    "        original_id = base_id\n",
    "        counter = 1\n",
    "        while base_id in self.main_database[\"records\"]:\n",
    "            base_id = f\"{original_id}_{counter}\"\n",
    "            counter += 1\n",
    "        \n",
    "        return base_id\n",
    "    \n",
    "    def add_single_record(self, json_file_path: str) -> bool:\n",
    "        \"\"\"Bitta JSON faylni qo'shish\"\"\"\n",
    "        try:\n",
    "            with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "                record = json.load(file)\n",
    "            \n",
    "            filename = os.path.basename(json_file_path)\n",
    "            unique_id = self.generate_unique_id(record, filename)\n",
    "            \n",
    "            # Record'ga unique ID ni qo'yish\n",
    "            record[\"utt_id\"] = unique_id\n",
    "            record[\"source_file\"] = filename\n",
    "            record[\"added_at\"] = datetime.now().isoformat()\n",
    "            \n",
    "            # Ma'lumotlar bazasiga qo'shish\n",
    "            self.main_database[\"records\"][unique_id] = record\n",
    "            self.main_database[\"metadata\"][\"total_records\"] += 1\n",
    "            self.main_database[\"metadata\"][\"last_updated\"] = datetime.now().isoformat()\n",
    "            \n",
    "            print(f\"‚úì Qo'shildi: {filename} -> ID: {unique_id}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Xatolik {json_file_path}: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def add_multiple_records(self, json_files: List[str]) -> Dict[str, int]:\n",
    "        \"\"\"Ko'plab JSON fayllarni qo'shish\"\"\"\n",
    "        stats = {\"success\": 0, \"failed\": 0}\n",
    "        \n",
    "        for json_file in json_files:\n",
    "            if self.add_single_record(json_file):\n",
    "                stats[\"success\"] += 1\n",
    "            else:\n",
    "                stats[\"failed\"] += 1\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def add_from_directory(self, directory_path: str) -> Dict[str, int]:\n",
    "        \"\"\"Papkadan barcha JSON fayllarni qo'shish\"\"\"\n",
    "        json_files = []\n",
    "        \n",
    "        for filename in os.listdir(directory_path):\n",
    "            if filename.endswith('.json'):\n",
    "                json_files.append(os.path.join(directory_path, filename))\n",
    "        \n",
    "        if not json_files:\n",
    "            print(\"JSON fayllar topilmadi!\")\n",
    "            return {\"success\": 0, \"failed\": 0}\n",
    "        \n",
    "        print(f\"Topildi: {len(json_files)} ta JSON fayl\")\n",
    "        return self.add_multiple_records(json_files)\n",
    "    \n",
    "    def search_records(self, **criteria) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Ma'lumotlarni qidirish\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for record_id, record in self.main_database[\"records\"].items():\n",
    "            match = True\n",
    "            for key, value in criteria.items():\n",
    "                if key not in record or record[key] != value:\n",
    "                    match = False\n",
    "                    break\n",
    "            \n",
    "            if match:\n",
    "                results.append(record)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Statistikalarni olish\"\"\"\n",
    "        records = self.main_database[\"records\"]\n",
    "        \n",
    "        categories = {}\n",
    "        sentiments = {}\n",
    "        speakers = {}\n",
    "        \n",
    "        for record in records.values():\n",
    "            # Kategoriya bo'yicha\n",
    "            cat = record.get(\"category\", \"unknown\")\n",
    "            categories[cat] = categories.get(cat, 0) + 1\n",
    "            \n",
    "            # Sentiment bo'yicha\n",
    "            sent = record.get(\"sentiment\", \"unknown\")\n",
    "            sentiments[sent] = sentiments.get(sent, 0) + 1\n",
    "            \n",
    "            # Speaker bo'yicha\n",
    "            speaker = record.get(\"speaker_id\", \"unknown\")\n",
    "            speakers[speaker] = speakers.get(speaker, 0) + 1\n",
    "        \n",
    "        return {\n",
    "            \"total_records\": len(records),\n",
    "            \"categories\": categories,\n",
    "            \"sentiments\": sentiments,\n",
    "            \"speakers\": speakers,\n",
    "            \"last_updated\": self.main_database[\"metadata\"][\"last_updated\"]\n",
    "        }\n",
    "    \n",
    "    def export_to_format(self, format_type: str = \"list\") -> Any:\n",
    "        \"\"\"Ma'lumotlarni eksport qilish\"\"\"\n",
    "        if format_type == \"list\":\n",
    "            return list(self.main_database[\"records\"].values())\n",
    "        elif format_type == \"dict\":\n",
    "            return self.main_database[\"records\"]\n",
    "        else:\n",
    "            return self.main_database\n",
    "\n",
    "def main():\n",
    "    \"\"\"Asosiy funksiya - dasturni ishga tushirish\"\"\"\n",
    "    manager = AudioDataManager()\n",
    "    \n",
    "    print(\"=== Audio Ma'lumotlar Boshqaruvchi ===\")\n",
    "    print(\"1. Bitta fayl qo'shish\")\n",
    "    print(\"2. Papkadan barcha fayllarni qo'shish\")\n",
    "    print(\"3. Statistikalarni ko'rish\")\n",
    "    print(\"4. Ma'lumotlarni saqlash va chiqish\")\n",
    "    \n",
    "    while True:\n",
    "        choice = input(\"\\nTanlang (1-4): \").strip()\n",
    "        \n",
    "        if choice == \"1\":\n",
    "            file_path = input(\"JSON fayl yo'lini kiriting: \").strip()\n",
    "            if os.path.exists(file_path):\n",
    "                manager.add_single_record(file_path)\n",
    "                manager.save_main_database()\n",
    "            else:\n",
    "                print(\"Fayl topilmadi!\")\n",
    "        \n",
    "        elif choice == \"2\":\n",
    "            dir_path = input(\"Papka yo'lini kiriting: \").strip()\n",
    "            if os.path.exists(dir_path):\n",
    "                stats = manager.add_from_directory(dir_path)\n",
    "                print(f\"\\nNatija: {stats['success']} muvaffaqiyatli, {stats['failed']} xato\")\n",
    "                manager.save_main_database()\n",
    "            else:\n",
    "                print(\"Papka topilmadi!\")\n",
    "        \n",
    "        elif choice == \"3\":\n",
    "            stats = manager.get_statistics()\n",
    "            print(\"\\n=== Statistikalar ===\")\n",
    "            print(f\"Jami yozuvlar: {stats['total_records']}\")\n",
    "            print(f\"Kategoriyalar: {stats['categories']}\")\n",
    "            print(f\"Kayfiyat: {stats['sentiments']}\")\n",
    "            print(f\"So'nggi yangilanish: {stats['last_updated']}\")\n",
    "        \n",
    "        elif choice == \"4\":\n",
    "            manager.save_main_database()\n",
    "            print(\"Ma'lumotlar saqlandi. Dastur tugadi.\")\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            print(\"Noto'g'ri tanlov!\")\n",
    "\n",
    "# Qo'shimcha utility funksiyalar\n",
    "def batch_process_directory(directory_path: str, output_path: str = \"merged_audio_data.json\"):\n",
    "    \"\"\"Papkadagi barcha JSON fayllarni avtomatik birlashtirish\"\"\"\n",
    "    manager = AudioDataManager(output_path)\n",
    "    stats = manager.add_from_directory(directory_path)\n",
    "    manager.save_main_database()\n",
    "    \n",
    "    print(f\"Natija: {stats['success']} fayl birlashtirildi\")\n",
    "    print(f\"Saqlandi: {output_path}\")\n",
    "    \n",
    "    return manager\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfc701d",
   "metadata": {},
   "source": [
    "## simple_merger.py - Sodda birlashtiruvchi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4ccbf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON fayllar papkasi: drive-download-20250915T152939Z-1-001\n",
      "6 ta fayl birlashtirildi -> merged_data.json\n"
     ]
    }
   ],
   "source": [
    "# simple_merger.py - Sodda birlashtiruvchi\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def merge_json_files(input_directory, output_file=\"merged_data.json\"):\n",
    "    \"\"\"Sodda JSON fayllar birlashtiruvi\"\"\"\n",
    "    merged_data = []\n",
    "    processed_files = 0\n",
    "    \n",
    "    for filename in os.listdir(input_directory):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(input_directory, filename)\n",
    "            \n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                # Agar utt_id yo'q bo'lsa, fayl nomidan yaratamiz\n",
    "                if 'utt_id' not in data:\n",
    "                    data['utt_id'] = os.path.splitext(filename)[0]\n",
    "                \n",
    "                data['source_file'] = filename\n",
    "                merged_data.append(data)\n",
    "                processed_files += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Xatolik {filename}: {e}\")\n",
    "    \n",
    "    # Saqlash\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(merged_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"{processed_files} ta fayl birlashtirildi -> {output_file}\")\n",
    "\n",
    "# Ishlatish\n",
    "if __name__ == \"__main__\":\n",
    "    input_dir = input(\"JSON fayllar papkasi: \")\n",
    "    merge_json_files(input_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004c490e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Oddiy ishlatish:\n",
    "\n",
    "`bash`\n",
    "\n",
    "python simple_merger.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a8e813",
   "metadata": {},
   "source": [
    "## Kengaytirilgan ishlatish "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2592b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_data_manager import AudioDataManager\n",
    "\n",
    "# Manager yaratish\n",
    "manager = AudioDataManager(\"my_database.json\")\n",
    "\n",
    "# Papkadan fayllarni qo'shish\n",
    "stats = manager.add_from_directory(\"/path/to/json/files\")\n",
    "\n",
    "# Saqlash\n",
    "manager.save_main_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9d9969",
   "metadata": {},
   "source": [
    "# Telegram botda foydalanuvchilar bir xil matnni qayta-qayta yozib olishi mumkin va bu holatda takroriy matnlarni aniqlash kerak. \n",
    "## Bu holat uchun text duplicate detection funksiyasini qo'shamiz"
   ]
  },
  {
   "cell_type": "code",
   "id": "adda588a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T18:35:00.419914Z",
     "start_time": "2025-09-16T18:31:29.928555Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Tuple\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "\n",
    "class SmartAudioDataManager:\n",
    "    def __init__(self, main_db_path: str = \"main_audio_database.json\", \n",
    "                 similarity_threshold: float = 0.85):\n",
    "        \"\"\"\n",
    "        Aqlli audio ma'lumotlar boshqaruvchi\n",
    "        main_db_path: asosiy ma'lumotlar bazasi\n",
    "        similarity_threshold: matn o'xshashlik chegarasi (0.0-1.0)\n",
    "        \"\"\"\n",
    "        self.main_db_path = main_db_path\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.main_database = self.load_main_database()\n",
    "    \n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"Matnni taqqoslash uchun tozalash\"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        \n",
    "        # Kichik harfga o'tkazish\n",
    "        text = text.lower().strip()\n",
    "        \n",
    "        # Ortiqcha bo'shliqlarni olib tashlash\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        \n",
    "        # Tinish belgilarini olib tashlash\n",
    "        text = re.sub(r'[.,!?;:\"\"\"''‚Äû\"¬´¬ª]', '', text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def calculate_text_similarity(self, text1: str, text2: str) -> float:\n",
    "        \"\"\"Ikki matn orasidagi o'xshashlikni hisoblash\"\"\"\n",
    "        clean_text1 = self.clean_text(text1)\n",
    "        clean_text2 = self.clean_text(text2)\n",
    "        \n",
    "        if not clean_text1 or not clean_text2:\n",
    "            return 0.0\n",
    "        \n",
    "        # SequenceMatcher yordamida o'xshashlikni hisoblash\n",
    "        similarity = SequenceMatcher(None,  clean_text1, clean_text2).ratio()\n",
    "        return similarity\n",
    "    \n",
    "    def create_text_hash(self, text: str) -> str:\n",
    "        \"\"\"Matn uchun hash yaratish\"\"\"\n",
    "        clean_text = self.clean_text(text)\n",
    "        return hashlib.md5(clean_text.encode('utf-8')).hexdigest()[:8]\n",
    "    \n",
    "    def find_similar_records(self, new_text: str) -> List[Tuple[str, Dict, float]]:\n",
    "        \"\"\"O'xshash matnlarni topish\"\"\"\n",
    "        similar_records = []\n",
    "        \n",
    "        for record_id, record in self.main_database[\"records\"].items():\n",
    "            existing_text = record.get(\"text\", \"\")\n",
    "            similarity = self.calculate_text_similarity(new_text, existing_text)\n",
    "            \n",
    "            if similarity >= self.similarity_threshold:\n",
    "                similar_records.append((record_id, record, similarity))\n",
    "        \n",
    "        # O'xshashlik darajasi bo'yicha saralash\n",
    "        similar_records.sort(key=lambda x: x[2], reverse=True)\n",
    "        return similar_records\n",
    "    \n",
    "    def load_main_database(self) -> Dict[str, Any]:\n",
    "        \"\"\"Ma'lumotlar bazasini yuklash\"\"\"\n",
    "        if os.path.exists(self.main_db_path):\n",
    "            try:\n",
    "                with open(self.main_db_path, 'r', encoding='utf-8') as file:\n",
    "                    data = json.load(file)\n",
    "                    if isinstance(data, list):\n",
    "                        new_format = {\n",
    "                            \"metadata\": {\n",
    "                                \"total_records\": len(data),\n",
    "                                \"last_updated\": datetime.now().isoformat(),\n",
    "                                \"version\": \"2.0\",\n",
    "                                \"duplicate_policy\": \"detect_and_mark\"\n",
    "                            },\n",
    "                            \"records\": {item.get(\"utt_id\", f\"record_{i}\"): item \n",
    "                                      for i, item in enumerate(data)},\n",
    "                            \"text_hashes\": {}\n",
    "                        }\n",
    "                        self.save_main_database(new_format)\n",
    "                        return new_format\n",
    "                    return data\n",
    "            except (json.JSONDecodeError, FileNotFoundError):\n",
    "                pass\n",
    "        \n",
    "        return {\n",
    "            \"metadata\": {\n",
    "                \"total_records\": 0,\n",
    "                \"last_updated\": datetime.now().isoformat(),\n",
    "                \"version\": \"2.0\",\n",
    "                \"duplicate_policy\": \"detect_and_mark\"\n",
    "            },\n",
    "            \"records\": {},\n",
    "            \"text_hashes\": {}  # Matn hashlari uchun\n",
    "        }\n",
    "    \n",
    "    def save_main_database(self, data: Dict[str, Any] = None):\n",
    "        \"\"\"Ma'lumotlar bazasini saqlash\"\"\"\n",
    "        if data is None:\n",
    "            data = self.main_database\n",
    "        \n",
    "        with open(self.main_db_path, 'w', encoding='utf-8') as file:\n",
    "            json.dump(data, file, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    def add_record_with_duplicate_check(self, json_file_path: str, \n",
    "                                      action_on_duplicate: str = \"ask\") -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Takroriy tekshiruv bilan record qo'shish\n",
    "        action_on_duplicate: 'ask', 'skip', 'add_anyway', 'update_existing'\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "                new_record = json.load(file)\n",
    "            \n",
    "            filename = os.path.basename(json_file_path)\n",
    "            new_text = new_record.get(\"text\", \"\")\n",
    "            \n",
    "            if not new_text:\n",
    "                return {\"status\": \"error\", \"message\": \"Matn topilmadi\"}\n",
    "            \n",
    "            # O'xshash matnlarni qidirish\n",
    "            similar_records = self.find_similar_records(new_text)\n",
    "            \n",
    "            result = {\n",
    "                \"status\": \"unknown\",\n",
    "                \"filename\": filename,\n",
    "                \"new_text\": new_text,\n",
    "                \"similar_count\": len(similar_records),\n",
    "                \"similar_records\": similar_records[:3]  # Eng o'xshash 3 tasini ko'rsatish\n",
    "            }\n",
    "            \n",
    "            if similar_records:\n",
    "                # O'xshash matnlar topildi\n",
    "                best_match = similar_records[0]\n",
    "                similarity_percent = int(best_match[2] * 100)\n",
    "                \n",
    "                result[\"best_match\"] = {\n",
    "                    \"id\": best_match[0],\n",
    "                    \"text\": best_match[1].get(\"text\", \"\"),\n",
    "                    \"similarity\": similarity_percent,\n",
    "                    \"speaker_id\": best_match[1].get(\"speaker_id\"),\n",
    "                    \"created_at\": best_match[1].get(\"created_at\")\n",
    "                }\n",
    "                \n",
    "                if action_on_duplicate == \"ask\":\n",
    "                    print(f\"\\nüîç O'XSHASH MATN TOPILDI!\")\n",
    "                    print(f\"Yangi matn: '{new_text}'\")\n",
    "                    print(f\"Mavjud matn: '{best_match[1].get('text', '')}'\")\n",
    "                    print(f\"O'xshashlik: {similarity_percent}%\")\n",
    "                    print(f\"Mavjud ID: {best_match[0]}\")\n",
    "                    \n",
    "                    choice = input(\"\\nHarakat tanlang:\\n1. Qo'shish (har xil audio)\\n2. O'tkazib yuborish\\n3. Mavjudini yangilash\\nTanlang (1-3): \").strip()\n",
    "                    \n",
    "                    if choice == \"1\":\n",
    "                        action_on_duplicate = \"add_anyway\"\n",
    "                    elif choice == \"2\":\n",
    "                        action_on_duplicate = \"skip\"\n",
    "                    elif choice == \"3\":\n",
    "                        action_on_duplicate = \"update_existing\"\n",
    "                    else:\n",
    "                        action_on_duplicate = \"skip\"\n",
    "                \n",
    "                # Tanlangan harakatni bajarish\n",
    "                if action_on_duplicate == \"skip\":\n",
    "                    result[\"status\"] = \"skipped\"\n",
    "                    result[\"message\"] = \"Takroriy matn, o'tkazib yuborildi\"\n",
    "                    return result\n",
    "                \n",
    "                elif action_on_duplicate == \"update_existing\":\n",
    "                    # Mavjud recordni yangilash\n",
    "                    existing_id = best_match[0]\n",
    "                    existing_record = self.main_database[\"records\"][existing_id]\n",
    "                    \n",
    "                    # Audio ma'lumotlarini yangilash\n",
    "                    if \"duration_ms\" in new_record:\n",
    "                        existing_record[\"duration_ms\"] = new_record[\"duration_ms\"]\n",
    "                    if \"created_at\" in new_record:\n",
    "                        existing_record[\"last_recorded_at\"] = new_record[\"created_at\"]\n",
    "                    \n",
    "                    existing_record[\"updated_at\"] = datetime.now().isoformat()\n",
    "                    existing_record[\"source_files\"] = existing_record.get(\"source_files\", []) + [filename]\n",
    "                    \n",
    "                    result[\"status\"] = \"updated\"\n",
    "                    result[\"message\"] = f\"Mavjud record yangilandi: {existing_id}\"\n",
    "                    result[\"updated_id\"] = existing_id\n",
    "                    return result\n",
    "            \n",
    "            # Yangi record qo'shish (o'xshash topilmadi yoki add_anyway tanlandi)\n",
    "            unique_id = self.generate_unique_id(new_record, filename)\n",
    "            \n",
    "            # Takroriy belgilar qo'shish\n",
    "            if similar_records:\n",
    "                new_record[\"is_potential_duplicate\"] = True\n",
    "                new_record[\"similar_to\"] = [r[0] for r in similar_records[:3]]\n",
    "                new_record[\"max_similarity\"] = similar_records[0][2]\n",
    "            else:\n",
    "                new_record[\"is_potential_duplicate\"] = False\n",
    "            \n",
    "            new_record[\"utt_id\"] = unique_id\n",
    "            new_record[\"source_file\"] = filename\n",
    "            new_record[\"added_at\"] = datetime.now().isoformat()\n",
    "            new_record[\"text_hash\"] = self.create_text_hash(new_text)\n",
    "            \n",
    "            # Ma'lumotlar bazasiga qo'shish\n",
    "            self.main_database[\"records\"][unique_id] = new_record\n",
    "            self.main_database[\"metadata\"][\"total_records\"] += 1\n",
    "            self.main_database[\"metadata\"][\"last_updated\"] = datetime.now().isoformat()\n",
    "            \n",
    "            # Text hash ni saqlash\n",
    "            text_hash = new_record[\"text_hash\"]\n",
    "            if text_hash not in self.main_database[\"text_hashes\"]:\n",
    "                self.main_database[\"text_hashes\"][text_hash] = []\n",
    "            self.main_database[\"text_hashes\"][text_hash].append(unique_id)\n",
    "            \n",
    "            result[\"status\"] = \"added\"\n",
    "            result[\"message\"] = f\"Yangi record qo'shildi: {unique_id}\"\n",
    "            result[\"new_id\"] = unique_id\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"status\": \"error\", \n",
    "                \"message\": f\"Xatolik: {str(e)}\",\n",
    "                \"filename\": os.path.basename(json_file_path)\n",
    "            }\n",
    "    \n",
    "    def generate_unique_id(self, record: Dict[str, Any], filename: str) -> str:\n",
    "        \"\"\"Noyob ID yaratish\"\"\"\n",
    "        if \"utt_id\" in record and record[\"utt_id\"]:\n",
    "            base_id = record[\"utt_id\"]\n",
    "        else:\n",
    "            base_id = os.path.splitext(filename)[0]\n",
    "        \n",
    "        original_id = base_id\n",
    "        counter = 1\n",
    "        while base_id in self.main_database[\"records\"]:\n",
    "            base_id = f\"{original_id}_{counter}\"\n",
    "            counter += 1\n",
    "        \n",
    "        return base_id\n",
    "    \n",
    "    def batch_process_with_duplicate_check(self, directory_path: str, \n",
    "                                         action_on_duplicate: str = \"ask\") -> Dict[str, Any]:\n",
    "        \"\"\"Papkadagi fayllarni takroriy tekshiruv bilan qayta ishlash\"\"\"\n",
    "        results = {\n",
    "            \"added\": 0,\n",
    "            \"skipped\": 0,\n",
    "            \"updated\": 0,\n",
    "            \"errors\": 0,\n",
    "            \"details\": []\n",
    "        }\n",
    "        \n",
    "        json_files = [f for f in os.listdir(directory_path) if f.endswith('.json')]\n",
    "        \n",
    "        if not json_files:\n",
    "            return {\"error\": \"JSON fayllar topilmadi\"}\n",
    "        \n",
    "        print(f\"Topildi: {len(json_files)} ta JSON fayl\")\n",
    "        \n",
    "        for i, filename in enumerate(json_files, 1):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            print(f\"\\n[{i}/{len(json_files)}] Qayta ishlanmoqda: {filename}\")\n",
    "            \n",
    "            result = self.add_record_with_duplicate_check(file_path, action_on_duplicate)\n",
    "            results[\"details\"].append(result)\n",
    "            \n",
    "            if result[\"status\"] == \"added\":\n",
    "                results[\"added\"] += 1\n",
    "                print(f\"‚úì Qo'shildi: {result.get('new_id', 'N/A')}\")\n",
    "            elif result[\"status\"] == \"skipped\":\n",
    "                results[\"skipped\"] += 1\n",
    "                print(f\"‚è≠ O'tkazib yuborildi: {result['message']}\")\n",
    "            elif result[\"status\"] == \"updated\":\n",
    "                results[\"updated\"] += 1\n",
    "                print(f\"üîÑ Yangilandi: {result.get('updated_id', 'N/A')}\")\n",
    "            else:\n",
    "                results[\"errors\"] += 1\n",
    "                print(f\"‚úó Xatolik: {result['message']}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def find_all_duplicates(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"Barcha takroriy matnlarni topish\"\"\"\n",
    "        text_groups = {}\n",
    "        \n",
    "        for record_id, record in self.main_database[\"records\"].items():\n",
    "            text = record.get(\"text\", \"\")\n",
    "            clean_text = self.clean_text(text)\n",
    "            \n",
    "            if clean_text:\n",
    "                if clean_text not in text_groups:\n",
    "                    text_groups[clean_text] = []\n",
    "                text_groups[clean_text].append(record_id)\n",
    "        \n",
    "        # Faqat takroriy bo'lganlarini qaytarish\n",
    "        duplicates = {text: ids for text, ids in text_groups.items() if len(ids) > 1}\n",
    "        return duplicates\n",
    "    \n",
    "    def get_duplicate_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Takroriy matnlar statistikasi\"\"\"\n",
    "        duplicates = self.find_all_duplicates()\n",
    "        \n",
    "        total_duplicate_groups = len(duplicates)\n",
    "        total_duplicate_records = sum(len(ids) for ids in duplicates.values())\n",
    "        \n",
    "        return {\n",
    "            \"total_records\": len(self.main_database[\"records\"]),\n",
    "            \"duplicate_groups\": total_duplicate_groups,\n",
    "            \"duplicate_records\": total_duplicate_records,\n",
    "            \"unique_records\": len(self.main_database[\"records\"]) - total_duplicate_records + total_duplicate_groups,\n",
    "            \"duplicate_details\": duplicates\n",
    "        }\n",
    "\n",
    "def main():\n",
    "    \"\"\"Asosiy dastur\"\"\"\n",
    "    print(\"Ma'lumotlar Boshqaruvchi\")\n",
    "    \n",
    "    # similarity = float(input(\"O'xshashlik chegarasi (0.7-0.95, tavsiya 0.85): \") or \"0.85\")\n",
    "    similarity=0.85\n",
    "    manager = SmartAudioDataManager(similarity_threshold=similarity)\n",
    "\n",
    "    \n",
    "    print(\"\\n1. Bitta fayl qo'shish (takroriy tekshiruv bilan)\")\n",
    "    print(\"2. Papkadan fayllarni qo'shish (takroriy tekshiruv bilan)\")  \n",
    "    print(\"3. Takroriy matnlar statistikasi\")\n",
    "    print(\"4. Barcha takroriylarni ko'rsatish\")\n",
    "    print(\"5. Ma'lumotlarni saqlash\")\n",
    "    \n",
    "    while True:\n",
    "        choice = input(\"\\nTanlang (1-5): \").strip()\n",
    "        \n",
    "        if choice == \"1\":\n",
    "            file_path = input(\"JSON fayl yo'li: \").strip()\n",
    "            if os.path.exists(file_path):\n",
    "                result = manager.add_record_with_duplicate_check(file_path)\n",
    "                print(f\"Natija: {result['message']}\")\n",
    "                manager.save_main_database()\n",
    "            else:\n",
    "                print(\"Fayl topilmadi!\")\n",
    "        \n",
    "        elif choice == \"2\":\n",
    "            dir_path = input(\"Papka yo'li: \").strip()\n",
    "            if os.path.exists(dir_path):\n",
    "                print(\"\\nTakroriy fayllar uchun harakat:\")\n",
    "                print(\"1. Har birini so'rash\")\n",
    "                print(\"2. Barchasini qo'shish\")\n",
    "                print(\"3. Barchasini o'tkazib yuborish\")\n",
    "\n",
    "                action_choice = input(\"Tanlang (1-3): \").strip()\n",
    "                action_map = {\"1\": \"ask\", \"2\": \"add_anyway\", \"3\": \"skip\"}\n",
    "                action = action_map.get(action_choice, \"ask\")\n",
    "                # action=\"skip\"\n",
    "\n",
    "                results = manager.batch_process_with_duplicate_check(dir_path, action)\n",
    "                print(f\"\\nüìä Natijalar:\")\n",
    "                print(f\"‚úì Qo'shildi: {results['added']}\")\n",
    "                print(f\"üîÑ Yangilandi: {results['updated']}\")\n",
    "                print(f\"‚è≠ O'tkazib yuborildi: {results['skipped']}\")\n",
    "                print(f\"‚úó Xatolar: {results['errors']}\")\n",
    "                \n",
    "                manager.save_main_database()\n",
    "            else:\n",
    "                print(\"Papka topilmadi!\")\n",
    "        \n",
    "        elif choice == \"3\":\n",
    "            stats = manager.get_duplicate_statistics()\n",
    "            print(f\"\\nüìà Takroriy matnlar statistikasi:\")\n",
    "            print(f\"Jami yozuvlar: {stats['total_records']}\")\n",
    "            print(f\"Takroriy guruhlar: {stats['duplicate_groups']}\")\n",
    "            print(f\"Takroriy yozuvlar: {stats['duplicate_records']}\")\n",
    "            print(f\"Noyob yozuvlar: {stats['unique_records']}\")\n",
    "        \n",
    "        elif choice == \"4\":\n",
    "            duplicates = manager.find_all_duplicates()\n",
    "            print(f\"\\nüìã Barcha takroriy matnlar ({len(duplicates)} ta guruh):\")\n",
    "            for i, (text, ids) in enumerate(duplicates.items(), 1):\n",
    "                print(f\"\\n{i}. '{text}' ({len(ids)} marta):\")\n",
    "                for record_id in ids:\n",
    "                    record = manager.main_database[\"records\"][record_id]\n",
    "                    print(f\"   - {record_id} | {record.get('created_at', 'N/A')}\")\n",
    "        \n",
    "        elif choice == \"5\":\n",
    "            manager.save_main_database()\n",
    "            print(\"Ma'lumotlar saqlandi!\")\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ma'lumotlar Boshqaruvchi\n",
      "\n",
      "1. Bitta fayl qo'shish (takroriy tekshiruv bilan)\n",
      "2. Papkadan fayllarni qo'shish (takroriy tekshiruv bilan)\n",
      "3. Takroriy matnlar statistikasi\n",
      "4. Barcha takroriylarni ko'rsatish\n",
      "5. Ma'lumotlarni saqlash\n",
      "\n",
      "Takroriy fayllar uchun harakat:\n",
      "1. Har birini so'rash\n",
      "2. Barchasini qo'shish\n",
      "3. Barchasini o'tkazib yuborish\n",
      "Topildi: 2 ta JSON fayl\n",
      "\n",
      "[1/2] Qayta ishlanmoqda: 20250912T124611_d9fafe5d.json\n",
      "\n",
      "üîç O'XSHASH MATN TOPILDI!\n",
      "Yangi matn: 'Bugun havo juda yaxshi, chiqaylikmi?'\n",
      "Mavjud matn: 'Bugun havo juda yaxshi, sayrga chiqaylikmi?'\n",
      "O'xshashlik: 90%\n",
      "Mavjud ID: 20250912T124607_d9fafe5d\n",
      "‚è≠ O'tkazib yuborildi: Takroriy matn, o'tkazib yuborildi\n",
      "\n",
      "[2/2] Qayta ishlanmoqda: 20250912T124612_fa67e4df.json\n",
      "\n",
      "üîç O'XSHASH MATN TOPILDI!\n",
      "Yangi matn: 'Samolyot chiptasi narxi oshib ketdi.'\n",
      "Mavjud matn: 'Samolyot chiptasi narxi oshib ketdi, afsus.'\n",
      "O'xshashlik: 92%\n",
      "Mavjud ID: 20250912T124632_fa67e4df\n",
      "‚è≠ O'tkazib yuborildi: Takroriy matn, o'tkazib yuborildi\n",
      "\n",
      "üìä Natijalar:\n",
      "‚úì Qo'shildi: 0\n",
      "üîÑ Yangilandi: 0\n",
      "‚è≠ O'tkazib yuborildi: 2\n",
      "‚úó Xatolar: 0\n",
      "Natija: Xatolik: [Errno 21] Is a directory: 'papka2'\n",
      "Natija: Xatolik: [Errno 21] Is a directory: 'papka3'\n",
      "Fayl topilmadi!\n",
      "\n",
      "üîç O'XSHASH MATN TOPILDI!\n",
      "Yangi matn: 'Bugun havo juda yaxshi, sayrga chiqaylikmi?'\n",
      "Mavjud matn: 'Bugun havo juda yaxshi, sayrga chiqaylikmi?'\n",
      "O'xshashlik: 100%\n",
      "Mavjud ID: 20250912T124607_d9fafe5d\n",
      "Natija: Takroriy matn, o'tkazib yuborildi\n",
      "Ma'lumotlar saqlandi!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd1229b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063b18bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
