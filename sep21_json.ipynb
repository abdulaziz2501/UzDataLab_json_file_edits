{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Json ma'lumotlar boshqaruvchi",
   "id": "83ca7e27999dcad3"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# streamlit_audio_manager.py\n",
    "import streamlit as st\n",
    "import json\n",
    "import os\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Tuple\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class SmartAudioDataManager:\n",
    "    def __init__(self, main_db_path: str = \"main_audio_database.json\",\n",
    "                 similarity_threshold: float = 0.85):\n",
    "        \"\"\"\n",
    "        main_db_path: asosiy ma'lumotlar bazasi\n",
    "        similarity_threshold: matn o'xshashlik chegarasi (0.0-1.0)\n",
    "        \"\"\"\n",
    "        self.main_db_path = main_db_path\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.main_database = self.load_main_database()\n",
    "\n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"Matnni taqqoslash uchun tozalash\"\"\"\n",
    "        if not text:\n",
    "            return \"\"\n",
    "\n",
    "        text = text.lower().strip()\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = re.sub(r'[.,!?;:\"\"\"''„\"«»]', '', text)\n",
    "\n",
    "        return text\n",
    "\n",
    "    def calculate_text_similarity(self, text1: str, text2: str) -> float:\n",
    "        \"\"\"Ikki matn orasidagi o'xshashlikni hisoblash\"\"\"\n",
    "        clean_text1 = self.clean_text(text1)\n",
    "        clean_text2 = self.clean_text(text2)\n",
    "\n",
    "        if not clean_text1 or not clean_text2:\n",
    "            return 0.0\n",
    "        similarity = SequenceMatcher(None, clean_text1, clean_text2).ratio()\n",
    "        return similarity\n",
    "\n",
    "    def create_text_hash(self, text: str) -> str:\n",
    "        \"\"\"Matn uchun hash yaratish\"\"\"\n",
    "        clean_text = self.clean_text(text)\n",
    "        return hashlib.md5(clean_text.encode('utf-8')).hexdigest()[:8]\n",
    "\n",
    "    def find_similar_records(self, new_text: str) -> List[Tuple[str, Dict, float]]:\n",
    "        \"\"\"O'xshash matnlarni topish\"\"\"\n",
    "        similar_records = []\n",
    "\n",
    "        for record_id, record in self.main_database[\"records\"].items():\n",
    "            existing_text = record.get(\"text\", \"\")\n",
    "            similarity = self.calculate_text_similarity(new_text, existing_text)\n",
    "\n",
    "            if similarity >= self.similarity_threshold:\n",
    "                similar_records.append((record_id, record, similarity))\n",
    "\n",
    "        similar_records.sort(key=lambda x: x[2], reverse=True)\n",
    "        return similar_records\n",
    "\n",
    "    def load_main_database(self) -> Dict[str, Any]:\n",
    "        \"\"\"Ma'lumotlar bazasini yuklash\"\"\"\n",
    "        if os.path.exists(self.main_db_path):\n",
    "            try:\n",
    "                with open(self.main_db_path, 'r', encoding='utf-8') as file:\n",
    "                    data = json.load(file)\n",
    "                    if isinstance(data, list):\n",
    "                        new_format = {\n",
    "                            \"metadata\": {\n",
    "                                \"total_records\": len(data),\n",
    "                                \"last_updated\": datetime.now().isoformat(),\n",
    "                                \"version\": \"2.0\",\n",
    "                                \"duplicate_policy\": \"detect_and_mark\"\n",
    "                            },\n",
    "                            \"records\": {item.get(\"utt_id\", f\"record_{i}\"): item\n",
    "                                        for i, item in enumerate(data)},\n",
    "                            \"text_hashes\": {}\n",
    "                        }\n",
    "                        self.save_main_database(new_format)\n",
    "                        return new_format\n",
    "                    return data\n",
    "            except (json.JSONDecodeError, FileNotFoundError):\n",
    "                pass\n",
    "\n",
    "        return {\n",
    "            \"metadata\": {\n",
    "                \"total_records\": 0,\n",
    "                \"last_updated\": datetime.now().isoformat(),\n",
    "                \"version\": \"2.0\",\n",
    "                \"duplicate_policy\": \"detect_and_mark\"\n",
    "            },\n",
    "            \"records\": {},\n",
    "            \"text_hashes\": {}\n",
    "        }\n",
    "\n",
    "    def save_main_database(self, data: Dict[str, Any] = None):\n",
    "        \"\"\"Ma'lumotlar bazasini saqlash\"\"\"\n",
    "        if data is None:\n",
    "            data = self.main_database\n",
    "\n",
    "        with open(self.main_db_path, 'w', encoding='utf-8') as file:\n",
    "            json.dump(data, file, ensure_ascii=False, indent=2)\n",
    "\n",
    "    def generate_unique_id(self, record: Dict[str, Any], filename: str) -> str:\n",
    "        \"\"\"ID yaratish\"\"\"\n",
    "        if \"utt_id\" in record and record[\"utt_id\"]:\n",
    "            base_id = record[\"utt_id\"]\n",
    "        else:\n",
    "            base_id = os.path.splitext(filename)[0]\n",
    "\n",
    "        original_id = base_id\n",
    "        counter = 1\n",
    "        while base_id in self.main_database[\"records\"]:\n",
    "            base_id = f\"{original_id}_{counter}\"\n",
    "            counter += 1\n",
    "\n",
    "        return base_id\n",
    "\n",
    "    def add_record_streamlit(self, new_record: dict, filename: str,\n",
    "                             action_on_duplicate: str = \"ask\") -> Dict[str, Any]:\n",
    "        \"\"\"Streamlit uchun record qo'shish\"\"\"\n",
    "        try:\n",
    "            new_text = new_record.get(\"text\", \"\")\n",
    "\n",
    "            if not new_text:\n",
    "                return {\"status\": \"error\", \"message\": \"Matn topilmadi\"}\n",
    "\n",
    "            similar_records = self.find_similar_records(new_text)\n",
    "\n",
    "            result = {\n",
    "                \"status\": \"unknown\",\n",
    "                \"filename\": filename,\n",
    "                \"new_text\": new_text,\n",
    "                \"similar_count\": len(similar_records),\n",
    "                \"similar_records\": similar_records[:3]\n",
    "            }\n",
    "\n",
    "            if similar_records:\n",
    "                best_match = similar_records[0]\n",
    "                similarity_percent = int(best_match[2] * 100)\n",
    "\n",
    "                result[\"best_match\"] = {\n",
    "                    \"id\": best_match[0],\n",
    "                    \"text\": best_match[1].get(\"text\", \"\"),\n",
    "                    \"similarity\": similarity_percent,\n",
    "                    \"speaker_id\": best_match[1].get(\"speaker_id\"),\n",
    "                    \"created_at\": best_match[1].get(\"created_at\")\n",
    "                }\n",
    "\n",
    "                if action_on_duplicate == \"skip\":\n",
    "                    result[\"status\"] = \"skipped\"\n",
    "                    result[\"message\"] = \"Takroriy matn, o'tkazib yuborildi\"\n",
    "                    return result\n",
    "\n",
    "                elif action_on_duplicate == \"update_existing\":\n",
    "                    existing_id = best_match[0]\n",
    "                    existing_record = self.main_database[\"records\"][existing_id]\n",
    "\n",
    "                    if \"duration_ms\" in new_record:\n",
    "                        existing_record[\"duration_ms\"] = new_record[\"duration_ms\"]\n",
    "                    if \"created_at\" in new_record:\n",
    "                        existing_record[\"last_recorded_at\"] = new_record[\"created_at\"]\n",
    "\n",
    "                    existing_record[\"updated_at\"] = datetime.now().isoformat()\n",
    "                    existing_record[\"source_files\"] = existing_record.get(\"source_files\", []) + [filename]\n",
    "\n",
    "                    result[\"status\"] = \"updated\"\n",
    "                    result[\"message\"] = f\"Mavjud record yangilandi: {existing_id}\"\n",
    "                    result[\"updated_id\"] = existing_id\n",
    "                    return result\n",
    "\n",
    "            # Yangi record qo'shish\n",
    "            unique_id = self.generate_unique_id(new_record, filename)\n",
    "\n",
    "            if similar_records:\n",
    "                new_record[\"is_potential_duplicate\"] = True\n",
    "                new_record[\"similar_to\"] = [r[0] for r in similar_records[:3]]\n",
    "                new_record[\"max_similarity\"] = similar_records[0][2]\n",
    "            else:\n",
    "                new_record[\"is_potential_duplicate\"] = False\n",
    "\n",
    "            new_record[\"utt_id\"] = unique_id\n",
    "            new_record[\"source_file\"] = filename\n",
    "            new_record[\"added_at\"] = datetime.now().isoformat()\n",
    "            new_record[\"text_hash\"] = self.create_text_hash(new_text)\n",
    "\n",
    "            self.main_database[\"records\"][unique_id] = new_record\n",
    "            self.main_database[\"metadata\"][\"total_records\"] += 1\n",
    "            self.main_database[\"metadata\"][\"last_updated\"] = datetime.now().isoformat()\n",
    "\n",
    "            text_hash = new_record[\"text_hash\"]\n",
    "            if text_hash not in self.main_database[\"text_hashes\"]:\n",
    "                self.main_database[\"text_hashes\"][text_hash] = []\n",
    "            self.main_database[\"text_hashes\"][text_hash].append(unique_id)\n",
    "\n",
    "            result[\"status\"] = \"added\"\n",
    "            result[\"message\"] = f\"Yangi record qo'shildi: {unique_id}\"\n",
    "            result[\"new_id\"] = unique_id\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"message\": f\"Xatolik: {str(e)}\",\n",
    "                \"filename\": filename\n",
    "            }\n",
    "\n",
    "    def find_all_duplicates(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"Barcha takroriy matnlarni topish\"\"\"\n",
    "        text_groups = {}\n",
    "\n",
    "        for record_id, record in self.main_database[\"records\"].items():\n",
    "            text = record.get(\"text\", \"\")\n",
    "            clean_text = self.clean_text(text)\n",
    "\n",
    "            if clean_text:\n",
    "                if clean_text not in text_groups:\n",
    "                    text_groups[clean_text] = []\n",
    "                text_groups[clean_text].append(record_id)\n",
    "\n",
    "        duplicates = {text: ids for text, ids in text_groups.items() if len(ids) > 1}\n",
    "        return duplicates\n",
    "\n",
    "    def get_duplicate_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Takroriy matnlar statistikasi\"\"\"\n",
    "        duplicates = self.find_all_duplicates()\n",
    "\n",
    "        total_duplicate_groups = len(duplicates)\n",
    "        total_duplicate_records = sum(len(ids) for ids in duplicates.values())\n",
    "\n",
    "        return {\n",
    "            \"total_records\": len(self.main_database[\"records\"]),\n",
    "            \"duplicate_groups\": total_duplicate_groups,\n",
    "            \"duplicate_records\": total_duplicate_records,\n",
    "            \"unique_records\": len(self.main_database[\"records\"]) - total_duplicate_records + total_duplicate_groups,\n",
    "            \"duplicate_details\": duplicates\n",
    "        }\n",
    "\n",
    "    def get_general_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Umumiy statistikalar\"\"\"\n",
    "        records = self.main_database[\"records\"]\n",
    "\n",
    "        # Kategoriya bo'yicha\n",
    "        categories = {}\n",
    "        sentiments = {}\n",
    "        speakers = {}\n",
    "        devices = {}\n",
    "        regions = {}\n",
    "        languages = {}\n",
    "        genders = {}\n",
    "\n",
    "        total_duration = 0\n",
    "\n",
    "        for record in records.values():\n",
    "            # Kategoriya\n",
    "            cat = record.get(\"category\", \"unknown\")\n",
    "            categories[cat] = categories.get(cat, 0) + 1\n",
    "\n",
    "            # Sentiment\n",
    "            sent = record.get(\"sentiment\", \"unknown\")\n",
    "            sentiments[sent] = sentiments.get(sent, 0) + 1\n",
    "\n",
    "            # Speaker\n",
    "            speaker = record.get(\"speaker_id\", \"unknown\")\n",
    "            speakers[speaker] = speakers.get(speaker, 0) + 1\n",
    "\n",
    "            # Device\n",
    "            device = record.get(\"device\", \"unknown\")\n",
    "            devices[device] = devices.get(device, 0) + 1\n",
    "\n",
    "            # Region\n",
    "            region = record.get(\"region\", \"unknown\")\n",
    "            regions[region] = regions.get(region, 0) + 1\n",
    "\n",
    "            # Language\n",
    "            lang = record.get(\"lang\", \"unknown\")\n",
    "            languages[lang] = languages.get(lang, 0) + 1\n",
    "\n",
    "            # Gender\n",
    "            gender = record.get(\"gender\", \"unknown\")\n",
    "            genders[gender] = genders.get(gender, 0) + 1\n",
    "\n",
    "            # Duration\n",
    "            duration = record.get(\"duration_ms\", 0)\n",
    "            if duration:\n",
    "                total_duration += duration\n",
    "\n",
    "        return {\n",
    "            \"total_records\": len(records),\n",
    "            \"total_duration_ms\": total_duration,\n",
    "            \"total_duration_minutes\": round(total_duration / 60000, 2),\n",
    "            \"total_duration_hours\": round(total_duration / 3600000, 2),\n",
    "            \"categories\": categories,\n",
    "            \"sentiments\": sentiments,\n",
    "            \"speakers\": speakers,\n",
    "            \"devices\": devices,\n",
    "            \"regions\": regions,\n",
    "            \"languages\": languages,\n",
    "            \"genders\": genders,\n",
    "            \"last_updated\": self.main_database[\"metadata\"][\"last_updated\"]\n",
    "        }\n",
    "\n",
    "    def get_speaker_statistics(self) -> Dict[str, Dict[str, Any]]:\n",
    "        \"\"\"Har bir speaker bo'yicha statistika\"\"\"\n",
    "        speaker_stats = {}\n",
    "\n",
    "        for record in self.main_database[\"records\"].values():\n",
    "            speaker_id = record.get(\"speaker_id\", \"unknown\")\n",
    "\n",
    "            if speaker_id not in speaker_stats:\n",
    "                speaker_stats[speaker_id] = {\n",
    "                    \"total_records\": 0,\n",
    "                    \"total_duration_ms\": 0,\n",
    "                    \"categories\": {},\n",
    "                    \"sentiments\": {},\n",
    "                    \"devices\": {},\n",
    "                    \"regions\": set(),\n",
    "                    \"languages\": set(),\n",
    "                    \"genders\": set(),\n",
    "                    \"first_record\": None,\n",
    "                    \"last_record\": None\n",
    "                }\n",
    "\n",
    "            stats = speaker_stats[speaker_id]\n",
    "            stats[\"total_records\"] += 1\n",
    "\n",
    "            # Duration\n",
    "            duration = record.get(\"duration_ms\", 0)\n",
    "            if duration:\n",
    "                stats[\"total_duration_ms\"] += duration\n",
    "\n",
    "            # Categories\n",
    "            category = record.get(\"category\", \"unknown\")\n",
    "            stats[\"categories\"][category] = stats[\"categories\"].get(category, 0) + 1\n",
    "\n",
    "            # Sentiments\n",
    "            sentiment = record.get(\"sentiment\", \"unknown\")\n",
    "            stats[\"sentiments\"][sentiment] = stats[\"sentiments\"].get(sentiment, 0) + 1\n",
    "\n",
    "            # Devices\n",
    "            device = record.get(\"device\", \"unknown\")\n",
    "            stats[\"devices\"][device] = stats[\"devices\"].get(device, 0) + 1\n",
    "\n",
    "            # Regions\n",
    "            if record.get(\"region\"):\n",
    "                stats[\"regions\"].add(record.get(\"region\"))\n",
    "\n",
    "            # Languages\n",
    "            if record.get(\"lang\"):\n",
    "                stats[\"languages\"].add(record.get(\"lang\"))\n",
    "\n",
    "            # Genders\n",
    "            if record.get(\"gender\"):\n",
    "                stats[\"genders\"].add(record.get(\"gender\"))\n",
    "\n",
    "            # Time tracking\n",
    "            created_at = record.get(\"created_at\")\n",
    "            if created_at:\n",
    "                if not stats[\"first_record\"] or created_at < stats[\"first_record\"]:\n",
    "                    stats[\"first_record\"] = created_at\n",
    "                if not stats[\"last_record\"] or created_at > stats[\"last_record\"]:\n",
    "                    stats[\"last_record\"] = created_at\n",
    "\n",
    "        # Convert sets to lists for JSON serialization\n",
    "        for speaker_id, stats in speaker_stats.items():\n",
    "            stats[\"regions\"] = list(stats[\"regions\"])\n",
    "            stats[\"languages\"] = list(stats[\"languages\"])\n",
    "            stats[\"genders\"] = list(stats[\"genders\"])\n",
    "            stats[\"duration_minutes\"] = round(stats[\"total_duration_ms\"] / 60000, 2)\n",
    "            stats[\"duration_hours\"] = round(stats[\"total_duration_ms\"] / 3600000, 2)\n",
    "\n",
    "        return speaker_stats\n",
    "\n",
    "\n",
    "def main():\n",
    "    st.set_page_config(\n",
    "        page_title=\"Audio Ma'lumotlar Boshqaruvchi\",\n",
    "        page_icon=\"🎵\",\n",
    "        layout=\"wide\"\n",
    "    )\n",
    "\n",
    "    st.title(\"🎵 Audio Ma'lumotlar Boshqaruvchi\")\n",
    "    st.markdown(\"---\")\n",
    "\n",
    "    # Sidebar sozlamalari\n",
    "    with st.sidebar:\n",
    "        st.header(\"⚙️ Sozlamalar\")\n",
    "        similarity_threshold = st.slider(\n",
    "            \"O'xshashlik chegarasi\",\n",
    "            min_value=0.5,\n",
    "            max_value=1.0,\n",
    "            value=0.85,\n",
    "            step=0.05,\n",
    "            help=\"Matnlar o'xshashligini belgilash chegarasi\"\n",
    "        )\n",
    "\n",
    "        db_file = st.text_input(\n",
    "            \"Ma'lumotlar bazasi fayli\",\n",
    "            value=\"main_audio_database.json\",\n",
    "            help=\"JSON ma'lumotlar bazasi fayl nomi\"\n",
    "        )\n",
    "\n",
    "        # Reset session state when settings change\n",
    "        if st.button(\"Sozlamalarni Qo'llash\"):\n",
    "            if 'manager' in st.session_state:\n",
    "                del st.session_state.manager\n",
    "            st.rerun()\n",
    "\n",
    "    # Manager obyektini yaratish\n",
    "    if 'manager' not in st.session_state or st.session_state.manager.similarity_threshold != similarity_threshold:\n",
    "        st.session_state.manager = SmartAudioDataManager(\n",
    "            main_db_path=db_file,\n",
    "            similarity_threshold=similarity_threshold\n",
    "        )\n",
    "\n",
    "    manager = st.session_state.manager\n",
    "\n",
    "    # Reset uploaded files after processing\n",
    "    if 'files_processed' not in st.session_state:\n",
    "        st.session_state.files_processed = False\n",
    "\n",
    "    # Tab'larni yaratish\n",
    "    tab1, tab2, tab3, tab4, tab5 = st.tabs([\n",
    "        \"📁 Fayl Qo'shish\",\n",
    "        \"📊 Umumiy Statistika\",\n",
    "        \"👥 Speaker Statistika\",\n",
    "        \"🔍 Takrorlar\",\n",
    "        \"💾 Ma'lumotlar\"\n",
    "    ])\n",
    "\n",
    "    with tab1:\n",
    "        st.header(\"Yangi Fayl Qo'shish\")\n",
    "\n",
    "        col1, col2 = st.columns([1, 1])\n",
    "\n",
    "        with col1:\n",
    "            st.subheader(\"Bitta Fayl\")\n",
    "            uploaded_file = st.file_uploader(\n",
    "                \"JSON fayl yuklang\",\n",
    "                type=['json'],\n",
    "                key=\"single_file\"\n",
    "            )\n",
    "\n",
    "            if uploaded_file:\n",
    "                try:\n",
    "                    file_content = json.loads(uploaded_file.read())\n",
    "\n",
    "                    with st.expander(\"Fayl tarkibi\"):\n",
    "                        st.json(file_content)\n",
    "\n",
    "                    duplicate_action = st.selectbox(\n",
    "                        \"Takroriy fayllar uchun harakat\",\n",
    "                        [\"add_anyway\", \"skip\", \"update_existing\"],\n",
    "                        format_func=lambda x: {\n",
    "                            \"add_anyway\": \"Qo'shish\",\n",
    "                            \"skip\": \"O'tkazish\",\n",
    "                            \"update_existing\": \"Yangilash\"\n",
    "                        }[x]\n",
    "                    )\n",
    "\n",
    "                    if st.button(\"Faylni Qo'shish\", type=\"primary\"):\n",
    "                        result = manager.add_record_streamlit(\n",
    "                            file_content,\n",
    "                            uploaded_file.name,\n",
    "                            duplicate_action\n",
    "                        )\n",
    "\n",
    "                        if result[\"status\"] == \"added\":\n",
    "                            st.success(result[\"message\"])\n",
    "                            manager.save_main_database()\n",
    "                        elif result[\"status\"] == \"skipped\":\n",
    "                            st.warning(result[\"message\"])\n",
    "                        elif result[\"status\"] == \"updated\":\n",
    "                            st.info(result[\"message\"])\n",
    "                            manager.save_main_database()\n",
    "                        else:\n",
    "                            st.error(result[\"message\"])\n",
    "\n",
    "                        # O'xshash yozuvlarni ko'rsatish\n",
    "                        if \"similar_records\" in result and result[\"similar_records\"]:\n",
    "                            st.subheader(\"O'xshash yozuvlar topildi:\")\n",
    "                            for i, (record_id, record, similarity) in enumerate(result[\"similar_records\"]):\n",
    "                                with st.expander(f\"O'xshashlik: {int(similarity * 100)}% - {record_id}\"):\n",
    "                                    st.write(f\"**Matn:** {record.get('text', '')}\")\n",
    "                                    st.write(f\"**Yaratilgan:** {record.get('created_at', 'N/A')}\")\n",
    "                                    st.write(f\"**Spiker ID:** {record.get('speaker_id', 'N/A')}\")\n",
    "\n",
    "                except json.JSONDecodeError:\n",
    "                    st.error(\"JSON fayl formati noto'g'ri!\")\n",
    "\n",
    "        with col2:\n",
    "            st.subheader(\"Bir nechta Fayl\")\n",
    "\n",
    "            # Clear file uploader when files are processed\n",
    "            if st.session_state.files_processed:\n",
    "                st.session_state.files_processed = False\n",
    "                st.rerun()\n",
    "\n",
    "            uploaded_files = st.file_uploader(\n",
    "                \"Bir nechta JSON fayl yuklang\",\n",
    "                type=['json'],\n",
    "                accept_multiple_files=True,\n",
    "                key=f\"multiple_files_{st.session_state.get('upload_key', 0)}\"\n",
    "            )\n",
    "\n",
    "            if uploaded_files:\n",
    "                st.write(f\"Tanlangan: {len(uploaded_files)} ta fayl\")\n",
    "\n",
    "                batch_action = st.selectbox(\n",
    "                    \"Batch ish uchun harakat\",\n",
    "                    [\"add_anyway\", \"skip\", \"update_existing\"],\n",
    "                    format_func=lambda x: {\n",
    "                        \"add_anyway\": \"Barchasini qo'shish\",\n",
    "                        \"skip\": \"Takrorlarni o'tkazish\",\n",
    "                        \"update_existing\": \"Takrorlarni yangilash\"\n",
    "                    }[x],\n",
    "                    key=\"batch_action\"\n",
    "                )\n",
    "\n",
    "                if st.button(\"Barcha Fayllarni Qayta Ishlash\", type=\"primary\"):\n",
    "                    progress_bar = st.progress(0)\n",
    "                    status_container = st.empty()\n",
    "                    results = {\"added\": 0, \"skipped\": 0, \"updated\": 0, \"errors\": 0, \"details\": []}\n",
    "\n",
    "                    for i, file in enumerate(uploaded_files):\n",
    "                        try:\n",
    "                            # Reset file pointer\n",
    "                            file.seek(0)\n",
    "                            file_content = json.loads(file.read())\n",
    "\n",
    "                            status_container.write(f\"Qayta ishlanmoqda: {file.name}\")\n",
    "\n",
    "                            result = manager.add_record_streamlit(\n",
    "                                file_content,\n",
    "                                file.name,\n",
    "                                batch_action\n",
    "                            )\n",
    "\n",
    "                            results[\"details\"].append(result)\n",
    "                            results[result[\"status\"]] += 1\n",
    "\n",
    "                            progress_bar.progress((i + 1) / len(uploaded_files))\n",
    "\n",
    "                        except json.JSONDecodeError:\n",
    "                            results[\"errors\"] += 1\n",
    "                            results[\"details\"].append({\n",
    "                                \"status\": \"error\",\n",
    "                                \"filename\": file.name,\n",
    "                                \"message\": \"JSON format xatosi\"\n",
    "                            })\n",
    "\n",
    "                    status_container.empty()\n",
    "\n",
    "                    # Natijalarni ko'rsatish\n",
    "                    col_a, col_b, col_c, col_d = st.columns(4)\n",
    "                    with col_a:\n",
    "                        st.metric(\"Qo'shildi\", results[\"added\"])\n",
    "                    with col_b:\n",
    "                        st.metric(\"Yangilandi\", results[\"updated\"])\n",
    "                    with col_c:\n",
    "                        st.metric(\"O'tkazildi\", results[\"skipped\"])\n",
    "                    with col_d:\n",
    "                        st.metric(\"Xatolar\", results[\"errors\"])\n",
    "\n",
    "                    manager.save_main_database()\n",
    "                    st.success(\"Batch qayta ishlash tugallandi!\")\n",
    "\n",
    "                    # Mark files as processed and increment upload key\n",
    "                    st.session_state.files_processed = True\n",
    "                    st.session_state.upload_key = st.session_state.get('upload_key', 0) + 1\n",
    "\n",
    "    with tab2:\n",
    "        st.header(\"📊 Umumiy Statistika\")\n",
    "\n",
    "        stats = manager.get_general_statistics()\n",
    "        duplicate_stats = manager.get_duplicate_statistics()\n",
    "\n",
    "        # Asosiy ko'rsatkichlar\n",
    "        col1, col2, col3, col4 = st.columns(4)\n",
    "        with col1:\n",
    "            st.metric(\"Jami Yozuvlar\", stats[\"total_records\"])\n",
    "        with col2:\n",
    "            st.metric(\"Jami Vaqt (soat)\", f\"{stats['total_duration_hours']:.1f}\")\n",
    "        with col3:\n",
    "            st.metric(\"Takroriy Guruhlar\", duplicate_stats[\"duplicate_groups\"])\n",
    "        with col4:\n",
    "            st.metric(\"Noyob Yozuvlar\", duplicate_stats[\"unique_records\"])\n",
    "\n",
    "        # Qo'shimcha ma'lumotlar\n",
    "        col1, col2 = st.columns(2)\n",
    "\n",
    "        with col1:\n",
    "            st.subheader(\"Kategoriyalar\")\n",
    "            if stats[\"categories\"]:\n",
    "                df_categories = pd.DataFrame(list(stats[\"categories\"].items()),\n",
    "                                           columns=[\"Kategoriya\", \"Soni\"])\n",
    "                st.bar_chart(df_categories.set_index(\"Kategoriya\"))\n",
    "            else:\n",
    "                st.info(\"Ma'lumot yo'q\")\n",
    "\n",
    "            st.subheader(\"Hissiyotlar\")\n",
    "            if stats[\"sentiments\"]:\n",
    "                df_sentiments = pd.DataFrame(list(stats[\"sentiments\"].items()),\n",
    "                                           columns=[\"Hissiyot\", \"Soni\"])\n",
    "                st.bar_chart(df_sentiments.set_index(\"Hissiyot\"))\n",
    "            else:\n",
    "                st.info(\"Ma'lumot yo'q\")\n",
    "\n",
    "        with col2:\n",
    "            st.subheader(\"Qurilmalar\")\n",
    "            if stats[\"devices\"]:\n",
    "                df_devices = pd.DataFrame(list(stats[\"devices\"].items()),\n",
    "                                        columns=[\"Qurilma\", \"Soni\"])\n",
    "                st.bar_chart(df_devices.set_index(\"Qurilma\"))\n",
    "            else:\n",
    "                st.info(\"Ma'lumot yo'q\")\n",
    "\n",
    "            st.subheader(\"Hududlar\")\n",
    "            if stats[\"regions\"]:\n",
    "                df_regions = pd.DataFrame(list(stats[\"regions\"].items()),\n",
    "                                        columns=[\"Hudud\", \"Soni\"])\n",
    "                st.bar_chart(df_regions.set_index(\"Hudud\"))\n",
    "            else:\n",
    "                st.info(\"Ma'lumot yo'q\")\n",
    "\n",
    "        # Ma'lumotlar bazasi metadata\n",
    "        st.subheader(\"Ma'lumotlar Bazasi Haqida\")\n",
    "        metadata = manager.main_database.get(\"metadata\", {})\n",
    "\n",
    "        col1, col2 = st.columns(2)\n",
    "        with col1:\n",
    "            st.write(f\"**Versiya:** {metadata.get('version', 'N/A')}\")\n",
    "            st.write(f\"**So'nggi Yangilanish:** {metadata.get('last_updated', 'N/A')}\")\n",
    "        with col2:\n",
    "            st.write(f\"**Takroriy Siyosat:** {metadata.get('duplicate_policy', 'N/A')}\")\n",
    "            st.write(f\"**O'xshashlik Chegarasi:** {similarity_threshold}\")\n",
    "\n",
    "    with tab3:\n",
    "        st.header(\"👥 Speaker Bo'yicha Statistika\")\n",
    "\n",
    "        speaker_stats = manager.get_speaker_statistics()\n",
    "\n",
    "        if speaker_stats:\n",
    "            # Umumiy speaker ko'rsatkichlari\n",
    "            st.subheader(\"Umumiy Ko'rsatkichlar\")\n",
    "            col1, col2, col3, col4 = st.columns(4)\n",
    "\n",
    "            with col1:\n",
    "                st.metric(\"Jami Speakerlar\", len(speaker_stats))\n",
    "            with col2:\n",
    "                total_speaker_records = sum(stats[\"total_records\"] for stats in speaker_stats.values())\n",
    "                st.metric(\"Jami Yozuvlar\", total_speaker_records)\n",
    "            with col3:\n",
    "                total_speaker_duration = sum(stats[\"total_duration_ms\"] for stats in speaker_stats.values())\n",
    "                st.metric(\"Jami Vaqt (soat)\", f\"{total_speaker_duration/3600000:.1f}\")\n",
    "            with col4:\n",
    "                avg_per_speaker = total_speaker_records / len(speaker_stats)\n",
    "                st.metric(\"O'rtacha/Speaker\", f\"{avg_per_speaker:.1f}\")\n",
    "\n",
    "            # Speaker tanlash\n",
    "            st.subheader(\"Speaker Tafsilotlari\")\n",
    "            speaker_ids = list(speaker_stats.keys())\n",
    "            selected_speaker = st.selectbox(\"Speakerni tanlang:\", speaker_ids)\n",
    "\n",
    "            if selected_speaker and selected_speaker in speaker_stats:\n",
    "                speaker_data = speaker_stats[selected_speaker]\n",
    "\n",
    "                # Tanlangan speaker statistikasi\n",
    "                col1, col2, col3, col4 = st.columns(4)\n",
    "                with col1:\n",
    "                    st.metric(\"Yozuvlar Soni\", speaker_data[\"total_records\"])\n",
    "                with col2:\n",
    "                    st.metric(\"Jami Vaqt (daqiqa)\", f\"{speaker_data['duration_minutes']:.1f}\")\n",
    "                with col3:\n",
    "                    st.metric(\"Birinchi Yozuv\", speaker_data[\"first_record\"][:10] if speaker_data[\"first_record\"] else \"N/A\")\n",
    "                with col4:\n",
    "                    st.metric(\"So'nggi Yozuv\", speaker_data[\"last_record\"][:10] if speaker_data[\"last_record\"] else \"N/A\")\n",
    "\n",
    "                # Tafsilotli ma'lumotlar\n",
    "                col1, col2 = st.columns(2)\n",
    "\n",
    "                with col1:\n",
    "                    if speaker_data[\"categories\"]:\n",
    "                        st.subheader(\"Kategoriyalar\")\n",
    "                        df_cat = pd.DataFrame(list(speaker_data[\"categories\"].items()),\n",
    "                                            columns=[\"Kategoriya\", \"Soni\"])\n",
    "                        st.bar_chart(df_cat.set_index(\"Kategoriya\"))\n",
    "\n",
    "                    if speaker_data[\"devices\"]:\n",
    "                        st.subheader(\"Qurilmalar\")\n",
    "                        df_dev = pd.DataFrame(list(speaker_data[\"devices\"].items()),\n",
    "                                            columns=[\"Qurilma\", \"Soni\"])\n",
    "                        st.bar_chart(df_dev.set_index(\"Qurilma\"))\n",
    "\n",
    "                with col2:\n",
    "                    if speaker_data[\"sentiments\"]:\n",
    "                        st.subheader(\"Hissiyotlar\")\n",
    "                        df_sent = pd.DataFrame(list(speaker_data[\"sentiments\"].items()),\n",
    "                                             columns=[\"Hissiyot\", \"Soni\"])\n",
    "                        st.bar_chart(df_sent.set_index(\"Hissiyot\"))\n",
    "\n",
    "                    st.subheader(\"Qo'shimcha Ma'lumotlar\")\n",
    "                    st.write(f\"**Hududlar:** {', '.join(speaker_data['regions']) if speaker_data['regions'] else 'N/A'}\")\n",
    "                    st.write(f\"**Tillar:** {', '.join(speaker_data['languages']) if speaker_data['languages'] else 'N/A'}\")\n",
    "                    st.write(f\"**Jinslar:** {', '.join(speaker_data['genders']) if speaker_data['genders'] else 'N/A'}\")\n",
    "\n",
    "            # Eng faol speakerlar\n",
    "            st.subheader(\"Eng Faol Speakerlar\")\n",
    "            speaker_list = []\n",
    "            for speaker_id, stats in speaker_stats.items():\n",
    "                speaker_list.append({\n",
    "                    \"Speaker ID\": speaker_id,\n",
    "                    \"Yozuvlar\": stats[\"total_records\"],\n",
    "                    \"Vaqt (daq)\": stats[\"duration_minutes\"],\n",
    "                    \"Kategoriyalar\": len(stats[\"categories\"]),\n",
    "                    \"So'nggi faollik\": stats[\"last_record\"][:10] if stats[\"last_record\"] else \"N/A\"\n",
    "                })\n",
    "\n",
    "            df_speakers = pd.DataFrame(speaker_list)\n",
    "            df_speakers = df_speakers.sort_values(\"Yozuvlar\", ascending=False)\n",
    "            st.dataframe(df_speakers, use_container_width=True)\n",
    "\n",
    "        else:\n",
    "            st.info(\"Hozircha speaker ma'lumotlari yo'q!\")\n",
    "\n",
    "    with tab4:\n",
    "        st.header(\"🔍 Takroriy Matnlar\")\n",
    "\n",
    "        duplicates = manager.find_all_duplicates()\n",
    "\n",
    "        if duplicates:\n",
    "            st.write(f\"Topilgan takroriy guruhlar: **{len(duplicates)}**\")\n",
    "\n",
    "            for i, (text, ids) in enumerate(duplicates.items(), 1):\n",
    "                with st.expander(f\"Guruh {i}: '{text}' ({len(ids)} marta)\"):\n",
    "                    for record_id in ids:\n",
    "                        record = manager.main_database[\"records\"][record_id]\n",
    "                        st.write(f\"**ID:** {record_id}\")\n",
    "                        st.write(f\"**Speaker ID:** {record.get('speaker_id', 'N/A')}\")\n",
    "                        st.write(f\"**Yaratilgan:** {record.get('created_at', 'N/A')}\")\n",
    "                        st.write(f\"**Manba Fayl:** {record.get('source_file', 'N/A')}\")\n",
    "                        st.write(\"---\")\n",
    "        else:\n",
    "            st.info(\"Takroriy matnlar topilmadi!\")\n",
    "\n",
    "    with tab5:\n",
    "        st.header(\"💾 Ma'lumotlar Boshqaruvi\")\n",
    "\n",
    "        col1, col2 = st.columns(2)\n",
    "\n",
    "        with col1:\n",
    "            st.subheader(\"Saqlash\")\n",
    "            if st.button(\"Ma'lumotlarni Saqlash\", type=\"primary\"):\n",
    "                try:\n",
    "                    manager.save_main_database()\n",
    "                    st.success(\"Ma'lumotlar muvaffaqiyatli saqlandi!\")\n",
    "                except Exception as e:\n",
    "                    st.error(f\"Saqlashda xatolik: {str(e)}\")\n",
    "\n",
    "            # Ma'lumotlar bazasini yuklab olish\n",
    "            if st.button(\"Bazani Yuklab Olish\"):\n",
    "                try:\n",
    "                    with open(manager.main_db_path, 'r', encoding='utf-8') as f:\n",
    "                        file_content = f.read()\n",
    "                        st.download_button(\n",
    "                            label=\"JSON Faylni Yuklab Olish\",\n",
    "                            data=file_content,\n",
    "                            file_name=f\"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\",\n",
    "                            mime=\"application/json\"\n",
    "                        )\n",
    "                except Exception as e:\n",
    "                    st.error(f\"Faylni o'qishda xatolik: {str(e)}\")\n",
    "\n",
    "        with col2:\n",
    "            st.subheader(\"Barcha Yozuvlarni Ko'rish\")\n",
    "            if st.button(\"Yozuvlarni Ko'rsatish\"):\n",
    "                if manager.main_database[\"records\"]:\n",
    "                    # DataFrame yaratish\n",
    "                    records_data = []\n",
    "                    for record_id, record in manager.main_database[\"records\"].items():\n",
    "                        records_data.append({\n",
    "                            \"ID\": record_id,\n",
    "                            \"Matn\": record.get(\"text\", \"\")[:100] + \"...\" if len(\n",
    "                                record.get(\"text\", \"\")) > 100 else record.get(\"text\", \"\"),\n",
    "                            \"Speaker ID\": record.get(\"speaker_id\", \"N/A\"),\n",
    "                            \"Yaratilgan\": record.get(\"created_at\", \"N/A\")[:10] if record.get(\"created_at\") else \"N/A\",\n",
    "                            \"Kategoriya\": record.get(\"category\", \"N/A\"),\n",
    "                            \"Takroriy\": \"Ha\" if record.get(\"is_potential_duplicate\", False) else \"Yo'q\"\n",
    "                        })\n",
    "\n",
    "                    df = pd.DataFrame(records_data)\n",
    "                    st.dataframe(df, use_container_width=True)\n",
    "                else:\n",
    "                    st.info(\"Hozircha yozuvlar yo'q!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "bf68694437f78b6a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
